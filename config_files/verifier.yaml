# Model arguments
torch_dtype: bfloat16
attn_implementation: sdpa

# Data arguments
chat_template: "{{ bos_token }}{% set system_messages = messages | selectattr('role', 'equalto', 'system') | selectattr('content', 'ne', '') | list %}{% if system_messages | length > 0 %}{% for message in system_messages %}{{ '<|start_header_id|>system<|end_header_id|>\n\n' + message['content'] + eos_token }}{% endfor %}{% endif %}{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|start_header_id|>user<|end_header_id|>\n\n' + message['content'] + eos_token }}{% elif message['role'] == 'assistant' %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n'  + message['content'] + eos_token }}{% endif %}{% if loop.last and add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{% endif %}{% endfor %}"
pad_token: <pad>
dataset_mixer:
  ./dataset/Llama-3.2-1B-Instruct.jsonl: 1.0
dataset_splits:
- train
preprocessing_num_workers: 64
keep_in_memory: false
load_from_cache_file: true
load_from_disk: true

# VerifierTrainer arguments
bf16: true
do_eval: false
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: False
learning_rate: 2.0e-05
log_level: info
logging_steps: 10
lr_scheduler_type: cosine
max_length: 2048
num_train_epochs: 2
output_dir: ./checkpoints/Llama-3.2-1B-Instruct-Verifier
overwrite_output_dir: true
push_to_hub: false
remove_unused_columns: false
save_strategy: "steps"
save_steps: 100
save_total_limit: 1
seed: 42
warmup_ratio: 0.1